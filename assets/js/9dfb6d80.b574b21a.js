"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([[529518],{15680:(e,r,t)=>{t.d(r,{xA:()=>u,yg:()=>g});var n=t(296540);function o(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function a(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function s(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?a(Object(t),!0).forEach((function(r){o(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function l(e,r){if(null==e)return{};var t,n,o=function(e,r){if(null==e)return{};var t,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||(o[t]=e[t]);return o}(e,r);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var i=n.createContext({}),c=function(e){var r=n.useContext(i),t=r;return e&&(t="function"==typeof e?e(r):s(s({},r),e)),t},u=function(e){var r=c(e.components);return n.createElement(i.Provider,{value:r},e.children)},m="mdxType",p={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},d=n.forwardRef((function(e,r){var t=e.components,o=e.mdxType,a=e.originalType,i=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),m=c(t),d=o,g=m["".concat(i,".").concat(d)]||m[d]||p[d]||a;return t?n.createElement(g,s(s({ref:r},u),{},{components:t})):n.createElement(g,s({ref:r},u))}));function g(e,r){var t=arguments,o=r&&r.mdxType;if("string"==typeof e||o){var a=t.length,s=new Array(a);s[0]=d;var l={};for(var i in r)hasOwnProperty.call(r,i)&&(l[i]=r[i]);l.originalType=e,l[m]="string"==typeof e?e:o,s[1]=l;for(var c=2;c<a;c++)s[c]=t[c];return n.createElement.apply(null,s)}return n.createElement.apply(null,t)}d.displayName="MDXCreateElement"},590587:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>i,contentTitle:()=>s,default:()=>p,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var n=t(58168),o=(t(296540),t(15680));const a={title:"Use Workload Group limit local IO",language:"en"},s=void 0,l={unversionedId:"admin-manual/resource-admin/use-workload-local-io-limit",id:"version-2.1/admin-manual/resource-admin/use-workload-local-io-limit",title:"Use Workload Group limit local IO",description:"\x3c!--",source:"@site/versioned_docs/version-2.1/admin-manual/resource-admin/use-workload-local-io-limit.md",sourceDirName:"admin-manual/resource-admin",slug:"/admin-manual/resource-admin/use-workload-local-io-limit",permalink:"/docs/admin-manual/resource-admin/use-workload-local-io-limit",draft:!1,tags:[],version:"2.1",frontMatter:{title:"Use Workload Group limit local IO",language:"en"},sidebar:"docs",previous:{title:"Use Workload Group limit CPU",permalink:"/docs/admin-manual/resource-admin/use-workload-cpu-limit"},next:{title:"Use Workload Group limit remote IO",permalink:"/docs/admin-manual/resource-admin/use-workload-remote-io-limit"}},i={},c=[{value:"Test limit local IO",id:"test-limit-local-io",level:2},{value:"Test",id:"test",level:3},{value:"Not limit IO",id:"not-limit-io",level:3},{value:"Test IO limit.",id:"test-io-limit",level:3},{value:"NOTE",id:"note",level:2}],u={toc:c},m="wrapper";function p(e){let{components:r,...a}=e;return(0,o.yg)(m,(0,n.A)({},u,a,{components:r,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"In OLAP systems, when performing ETL or large ad-hoc queries, a significant amount of data needs to be read. To speed up data analysis, Doris internally uses multithreading to scan multiple disk files in parallel, which generates a large amount of disk I/O and can negatively impact other queries, such as report analysis."),(0,o.yg)("p",null,"By using Workload Groups, you can group offline ETL data processing and online report queries separately and limit the I/O bandwidth for offline data processing, thereby reducing its impact on online report analysis."),(0,o.yg)("h2",{id:"test-limit-local-io"},"Test limit local IO"),(0,o.yg)("h3",{id:"test"},"Test"),(0,o.yg)("p",null,"1FE,1BE(96 cores), test data is clickbench"),(0,o.yg)("h3",{id:"not-limit-io"},"Not limit IO"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},"Clear cache.")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"// clear OS cache.\nsync; echo 3 > /proc/sys/vm/drop_caches\n\n// disable BE's cache.\ndisable_storage_page_cache = true\n")),(0,o.yg)("ol",{start:2},(0,o.yg)("li",{parentName:"ol"},"Run query one by one.")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"set dry_run_query = true;\nselect * from hits.hits;\n")),(0,o.yg)("ol",{start:3},(0,o.yg)("li",{parentName:"ol"},"Show local IO by system table, is's 3G/s.")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"mysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 1146.6208400726318 |\n+--------------------+\n1 row in set (0.03 sec)\n\nmysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 3496.2762966156006 |\n+--------------------+\n1 row in set (0.04 sec)\n\nmysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 2192.7690029144287 |\n+--------------------+\n1 row in set (0.02 sec)\n")),(0,o.yg)("p",null,"4.Show IO by pidstat, the first column in picture is process id, the second column is IO(kb/s), it's 2G/s."),(0,o.yg)("p",null,(0,o.yg)("img",{alt:"use workload group io",src:t(911543).A,width:"814",height:"1080"})),(0,o.yg)("h3",{id:"test-io-limit"},"Test IO limit."),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},"Clear cache.")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"// clear os cache\nsync; echo 3 > /proc/sys/vm/drop_caches\n\n// disable BE cache\ndisable_storage_page_cache = true\n")),(0,o.yg)("ol",{start:2},(0,o.yg)("li",{parentName:"ol"},"Alter workload group.")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"alter workload group g2 properties('read_bytes_per_second'='104857600');\n")),(0,o.yg)("ol",{start:3},(0,o.yg)("li",{parentName:"ol"},"Show IO by system table, it's about 98M/s.")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"mysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 97.94296646118164  |\n+--------------------+\n1 row in set (0.03 sec)\n\nmysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 98.37584781646729  |\n+--------------------+\n1 row in set (0.04 sec)\n\nmysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 98.06641292572021  |\n+--------------------+\n1 row in set (0.02 sec)\n")),(0,o.yg)("ol",{start:4},(0,o.yg)("li",{parentName:"ol"},"Show IO by pidstat, the process IO is about 131M/s\u3002")),(0,o.yg)("p",null,(0,o.yg)("img",{alt:"use workload group io",src:t(627260).A,width:"808",height:"676"})),(0,o.yg)("h2",{id:"note"},"NOTE"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},"The LOCAL_SCAN_BYTES_PER_SECOND field in the system table represents the aggregated statistics at the process level for the current Workload Group. For example, if 12 file paths are configured, LOCAL_SCAN_BYTES_PER_SECOND represents the maximum I/O value across these 12 file paths. If you want to see the I/O throughput for each file path individually, you can view detailed values in Grafana or through the BE's bvar monitoring."),(0,o.yg)("li",{parentName:"ol"},"Due to the presence of the operating system's and Doris's Page Cache, the I/O values observed using Linux's I/O monitoring scripts are usually smaller than those seen in the system table.")))}p.isMDXComponent=!0},911543:(e,r,t)=>{t.d(r,{A:()=>n});const n=t.p+"assets/images/use_wg_io_1-15b5d3e97f7ccf7f914eef0e6bf55cd4.png"},627260:(e,r,t)=>{t.d(r,{A:()=>n});const n=t.p+"assets/images/use_wg_io_2-2202fea206c596a3879c6660ada71037.png"}}]);