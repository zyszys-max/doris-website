"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([[42425],{15680:(e,t,a)=>{a.d(t,{xA:()=>s,yg:()=>m});var n=a(296540);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var p=n.createContext({}),d=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},s=function(e){var t=d(e.components);return n.createElement(p.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,l=e.originalType,p=e.parentName,s=i(e,["components","mdxType","originalType","parentName"]),c=d(a),g=o,m=c["".concat(p,".").concat(g)]||c[g]||u[g]||l;return a?n.createElement(m,r(r({ref:t},s),{},{components:a})):n.createElement(m,r({ref:t},s))}));function m(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var l=a.length,r=new Array(l);r[0]=g;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i[c]="string"==typeof e?e:o,r[1]=i;for(var d=2;d<l;d++)r[d]=a[d];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},410502:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>r,default:()=>u,frontMatter:()=>l,metadata:()=>i,toc:()=>d});var n=a(58168),o=(a(296540),a(15680));const l={title:"Compilation and Deployment",language:"en"},r=void 0,i={unversionedId:"compute-storage-decoupled/compilation-and-deployment",id:"version-3.0/compute-storage-decoupled/compilation-and-deployment",title:"Compilation and Deployment",description:"\x3c!--",source:"@site/versioned_docs/version-3.0/compute-storage-decoupled/compilation-and-deployment.md",sourceDirName:"compute-storage-decoupled",slug:"/compute-storage-decoupled/compilation-and-deployment",permalink:"/docs/3.0/compute-storage-decoupled/compilation-and-deployment",draft:!1,tags:[],version:"3.0",frontMatter:{title:"Compilation and Deployment",language:"en"},sidebar:"docs",previous:{title:"Doris Compute-Storage Decoupled Deployment Preparation",permalink:"/docs/3.0/compute-storage-decoupled/before-deployment"},next:{title:"Managing Storage Vault",permalink:"/docs/3.0/compute-storage-decoupled/managing-storage-vault"}},p={},d=[{value:"1. Overview",id:"1-overview",level:2},{value:"2. Obtaining Binaries",id:"2-obtaining-binaries",level:2},{value:"2.1 Direct Download",id:"21-direct-download",level:3},{value:"2.2 Compilation Output (Optional)",id:"22-compilation-output-optional",level:3},{value:"3. Meta Service Deployment",id:"3-meta-service-deployment",level:2},{value:"3.1 Configuration",id:"31-configuration",level:3},{value:"3.2 Start and Stop",id:"32-start-and-stop",level:3},{value:"4. Independent Deployment of Data Recycling Function (Optional)",id:"4-independent-deployment-of-data-recycling-function-optional",level:2},{value:"5. Startup Process for FE and BE",id:"5-startup-process-for-fe-and-be",level:2},{value:"5.1 Startup Order",id:"51-startup-order",level:3},{value:"5.2 Start the MASTER Role FE",id:"52-start-the-master-role-fe",level:3},{value:"5.2.1 Configure fe.conf",id:"521-configure-feconf",level:4},{value:"5.2.2 Start FE",id:"522-start-fe",level:4},{value:"5.3 Add Other FE Nodes",id:"53-add-other-fe-nodes",level:3},{value:"5.4 Add BE Nodes",id:"54-add-be-nodes",level:3},{value:"5.4.1 Configure be.conf",id:"541-configure-beconf",level:4},{value:"5.4.1 Start and Add BE",id:"541-start-and-add-be",level:4},{value:"6. Create Storage Vault",id:"6-create-storage-vault",level:2},{value:"6.1 Create HDFS Storage Vault",id:"61-create-hdfs-storage-vault",level:3},{value:"6.2 Create S3 Storage Vault",id:"62-create-s3-storage-vault",level:3},{value:"6.3 Set Default Storage Vault",id:"63-set-default-storage-vault",level:3},{value:"7. Notes",id:"7-notes",level:2}],s={toc:d},c="wrapper";function u(e){let{components:t,...a}=e;return(0,o.yg)(c,(0,n.A)({},s,a,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("h2",{id:"1-overview"},"1. Overview"),(0,o.yg)("p",null,"This document details the compilation and deployment process of Doris in a decoupled storage-compute model, highlighting the differences from the integrated storage-compute model, especially the compilation, configuration, and management of the newly added Meta Service (MS) module."),(0,o.yg)("h2",{id:"2-obtaining-binaries"},"2. Obtaining Binaries"),(0,o.yg)("h3",{id:"21-direct-download"},"2.1 Direct Download"),(0,o.yg)("p",null,"Compiled binaries (including all Doris modules) can be obtained from the ",(0,o.yg)("a",{parentName:"p",href:"https://doris.apache.org/download/"},"Doris Download Page")," (select version 3.0.2 or higher)."),(0,o.yg)("h3",{id:"22-compilation-output-optional"},"2.2 Compilation Output (Optional)"),(0,o.yg)("p",null,"Compile using the ",(0,o.yg)("inlineCode",{parentName:"p"},"build.sh")," script provided in the codebase. The new MS module is compiled with the ",(0,o.yg)("inlineCode",{parentName:"p"},"--cloud")," parameter."),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-shell"},"sh build.sh --fe --be --cloud \n")),(0,o.yg)("p",null,"After compilation, a new ",(0,o.yg)("inlineCode",{parentName:"p"},"ms")," directory will be added in the ",(0,o.yg)("inlineCode",{parentName:"p"},"output")," directory:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre"},"output\n\u251c\u2500\u2500 be\n\u251c\u2500\u2500 fe\n\u2514\u2500\u2500 ms\n    \u251c\u2500\u2500 bin\n    \u251c\u2500\u2500 conf\n    \u2514\u2500\u2500 lib\n")),(0,o.yg)("h2",{id:"3-meta-service-deployment"},"3. Meta Service Deployment"),(0,o.yg)("h3",{id:"31-configuration"},"3.1 Configuration"),(0,o.yg)("p",null,"In the ",(0,o.yg)("inlineCode",{parentName:"p"},"./conf/doris_cloud.conf")," file, you mainly need to modify the following two parameters:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"brpc_listen_port"),": The listening port for the Meta Service, default is 5000."),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("inlineCode",{parentName:"li"},"fdb_cluster"),": Connection information for the FoundationDB cluster, which can be obtained when deploying FoundationDB. (If using the ",(0,o.yg)("inlineCode",{parentName:"li"},"fdb_ctl.sh")," provided by Doris for deployment, this value can be found in the ",(0,o.yg)("inlineCode",{parentName:"li"},"$FDB_HOME/conf/fdb.cluster")," file.)")),(0,o.yg)("p",null,"Example configuration:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-Shell"},"brpc_listen_port = 5000\nfdb_cluster = xxx:yyy@127.0.0.1:4500\n")),(0,o.yg)("p",null,"Note: The value of ",(0,o.yg)("inlineCode",{parentName:"p"},"fdb_cluster")," should match the content of the ",(0,o.yg)("inlineCode",{parentName:"p"},"/etc/foundationdb/fdb.cluster")," file on the FoundationDB deployment machine. (If using the ",(0,o.yg)("inlineCode",{parentName:"p"},"fdb_ctl.sh")," provided by Doris for deployment, this value can be found in the ",(0,o.yg)("inlineCode",{parentName:"p"},"$FDB_HOME/conf/fdb.cluster")," file.)"),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Example: The last line of the file is the value to fill in the doris_cloud.conf for the fdb_cluster field")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-shell"},"cat /etc/foundationdb/fdb.cluster\n\n# DO NOT EDIT!\n# This file is auto-generated, it is not to be edited by hand.\ncloud_ssb:A83c8Y1S3ZbqHLL4P4HHNTTw0A83CuHj@127.0.0.1:4500\n")),(0,o.yg)("h3",{id:"32-start-and-stop"},"3.2 Start and Stop"),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"Environment Requirements")),(0,o.yg)("p",null,"Ensure that the ",(0,o.yg)("inlineCode",{parentName:"p"},"JAVA_HOME")," environment variable is correctly set to point to OpenJDK 17, and navigate to the ",(0,o.yg)("inlineCode",{parentName:"p"},"ms")," directory."),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"Start Command")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-Shell"},"export JAVA_HOME=${path_to_jdk_17}\nbin/start.sh --daemon\n")),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"Stop Command")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-shell"},"bin/stop.sh\n")),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"Verify Start")),(0,o.yg)("p",null,"Check the ",(0,o.yg)("inlineCode",{parentName:"p"},"doris_cloud.out")," file for the output message ",(0,o.yg)("inlineCode",{parentName:"p"},"successfully started"),"."),(0,o.yg)("p",null,"For production environment, please ensure that the total number of Meta Service is at least three."),(0,o.yg)("h2",{id:"4-independent-deployment-of-data-recycling-function-optional"},"4. Independent Deployment of Data Recycling Function (Optional)"),(0,o.yg)("admonition",{type:"info"},(0,o.yg)("p",{parentName:"admonition"},"The Meta Service itself has metadata management and recycling functions, which can be deployed independently. If you want to deploy them independently, you can refer to this section.")),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"Preparation Work")),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Create a new working directory (e.g., ",(0,o.yg)("inlineCode",{parentName:"p"},"recycler"),").")),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Copy the contents of the ",(0,o.yg)("inlineCode",{parentName:"p"},"ms")," directory to the new directory:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-shell"},"cp -r ms recycler\n")))),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"Configuration")),(0,o.yg)("p",null,"Modify the BRPC listening port ",(0,o.yg)("inlineCode",{parentName:"p"},"brpc_listen_port")," and the value of ",(0,o.yg)("inlineCode",{parentName:"p"},"fdb_cluster")," in the configuration file of the new directory."),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"Start Data Recycling Function")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-Shell"},"export JAVA_HOME=${path_to_jdk_17}\nbin/start.sh --recycler --daemon\n")),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"Start Only Metadata Operation Function")),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-Shell"},"export JAVA_HOME=${path_to_jdk_17}\nbin/start.sh --meta-service --daemon\n")),(0,o.yg)("h2",{id:"5-startup-process-for-fe-and-be"},"5. Startup Process for FE and BE"),(0,o.yg)("p",null,"This section details the steps to start FE (Frontend) and BE (Backend) in a decoupled storage-compute architecture."),(0,o.yg)("h3",{id:"51-startup-order"},"5.1 Startup Order"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},"Start the first FE instance with the MASTER role."),(0,o.yg)("li",{parentName:"ol"},"Add other FE and BE instances to the cluster."),(0,o.yg)("li",{parentName:"ol"},"Add the first Storage Vault.")),(0,o.yg)("h3",{id:"52-start-the-master-role-fe"},"5.2 Start the MASTER Role FE"),(0,o.yg)("h4",{id:"521-configure-feconf"},"5.2.1 Configure fe.conf"),(0,o.yg)("p",null,"In the ",(0,o.yg)("inlineCode",{parentName:"p"},"fe.conf")," file, the following key parameters need to be configured:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},(0,o.yg)("inlineCode",{parentName:"p"},"deploy_mode")),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"Description: Specifies the Doris startup mode."),(0,o.yg)("li",{parentName:"ul"},"Format: ",(0,o.yg)("inlineCode",{parentName:"li"},"cloud")," indicates the decoupled storage-compute mode; others indicate the integrated storage-compute mode."),(0,o.yg)("li",{parentName:"ul"},"Example: ",(0,o.yg)("inlineCode",{parentName:"li"},"cloud")))),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},(0,o.yg)("inlineCode",{parentName:"p"},"cluster_id")),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"Description: A unique identifier for the cluster in the decoupled storage-compute architecture; different clusters must set different cluster_ids."),(0,o.yg)("li",{parentName:"ul"},"Format: int type."),(0,o.yg)("li",{parentName:"ul"},"Example: ",(0,o.yg)("inlineCode",{parentName:"li"},"12345678")))),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},(0,o.yg)("inlineCode",{parentName:"p"},"meta_service_endpoint")),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"Description: The address and port of the Meta Service."),(0,o.yg)("li",{parentName:"ul"},"Format: ",(0,o.yg)("inlineCode",{parentName:"li"},"IP address:port number"),"."),(0,o.yg)("li",{parentName:"ul"},"Example: ",(0,o.yg)("inlineCode",{parentName:"li"},"127.0.0.1:5000"),", multiple meta services can be configured separated by commas.")))),(0,o.yg)("h4",{id:"522-start-fe"},"5.2.2 Start FE"),(0,o.yg)("p",null,"Example start command:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"bin/start_fe.sh --daemon\n")),(0,o.yg)("p",null,"The first FE process initializes the cluster and operates in the FOLLOWER role. Use a MySQL client to connect to the FE and use ",(0,o.yg)("inlineCode",{parentName:"p"},"show frontends")," to confirm that the recently started FE is the master."),(0,o.yg)("h3",{id:"53-add-other-fe-nodes"},"5.3 Add Other FE Nodes"),(0,o.yg)("p",null,"Other nodes should also modify the configuration file and start according to the above steps. Use a MySQL client to connect to the FE with the MASTER role and use the following SQL command to add additional FE nodes:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-sql"},'ALTER SYSTEM ADD FOLLOWER "host:port";\n')),(0,o.yg)("p",null,"Replace ",(0,o.yg)("inlineCode",{parentName:"p"},"host:port")," with the actual address and editlog port of the FE node. More information refer to ",(0,o.yg)("a",{parentName:"p",href:"/docs/3.0/sql-manual/sql-statements/Cluster-Management-Statements/ALTER-SYSTEM-ADD-FOLLOWER"},"ADD FOLLOWER")," and ",(0,o.yg)("a",{parentName:"p",href:"/docs/3.0/sql-manual/sql-statements/Cluster-Management-Statements/ALTER-SYSTEM-ADD-OBSERVER"},"ADD OBSERVER"),"."),(0,o.yg)("p",null,"For production environment, please ensure that the total number of Frontend (FE) nodes in the FOLLOWER role, including the first FE, remains an odd number. In general, three FOLLOWERS are sufficient. Frontend nodes in the OBSERVER role can be any number."),(0,o.yg)("h3",{id:"54-add-be-nodes"},"5.4 Add BE Nodes"),(0,o.yg)("p",null,"To add Backend nodes to the cluster, perform the following steps for each Backend:"),(0,o.yg)("h4",{id:"541-configure-beconf"},"5.4.1 Configure be.conf"),(0,o.yg)("p",null,"In the ",(0,o.yg)("inlineCode",{parentName:"p"},"be.conf")," file, the following key parameters need to be configured:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},(0,o.yg)("inlineCode",{parentName:"p"},"deploy_mode")),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"Description: Specifies the Doris startup mode."),(0,o.yg)("li",{parentName:"ul"},"Format: ",(0,o.yg)("inlineCode",{parentName:"li"},"cloud")," indicates the decoupled storage-compute mode; others indicate the integrated storage-compute mode."),(0,o.yg)("li",{parentName:"ul"},"Example: ",(0,o.yg)("inlineCode",{parentName:"li"},"cloud")))),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},(0,o.yg)("inlineCode",{parentName:"p"},"file_cache_path")),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"Description: The disk paths and other parameters used for file cache, represented as an array, with one entry for each disk. The ",(0,o.yg)("inlineCode",{parentName:"li"},"path")," specifies the disk path, and ",(0,o.yg)("inlineCode",{parentName:"li"},"total_size")," limits the size of the cache; -1 or 0 will use the entire disk space."),(0,o.yg)("li",{parentName:"ul"},"format: ",'[{"path":"/path/to/file_cache","total_size":21474836480},{"path":"/path/to/file_cache2","total_size":21474836480}]'),(0,o.yg)("li",{parentName:"ul"},"Example: ",'[{"path":"/path/to/file_cache","total_size":21474836480},{"path":"/path/to/file_cache2","total_size":21474836480}]'),(0,o.yg)("li",{parentName:"ul"},"Default: ",'[{"path":"${DORIS_HOME}/file_cache"}]')))),(0,o.yg)("h4",{id:"541-start-and-add-be"},"5.4.1 Start and Add BE"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Start the Backend:"),(0,o.yg)("p",{parentName:"li"},"Use the following command to start the Backend:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-bash"},"bin/start_be.sh --daemon\n"))),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Add the Backend to the cluster:"),(0,o.yg)("p",{parentName:"li"},"Connect to any Frontend using a MySQL client and execute:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-sql"},'ALTER SYSTEM ADD BACKEND "<ip>:<heartbeat_service_port>" [PROPERTIES properties];\n')),(0,o.yg)("p",{parentName:"li"},"Replace ",(0,o.yg)("inlineCode",{parentName:"p"},"<ip>")," with the IP address of the new Backend and ",(0,o.yg)("inlineCode",{parentName:"p"},"<heartbeat_service_port>")," with its configured heartbeat service port (default is 9050)."),(0,o.yg)("p",{parentName:"li"},"You can set the computing group for the BE using PROPERTIES."),(0,o.yg)("p",{parentName:"li"},"For more detailed usage, please refer to ",(0,o.yg)("a",{parentName:"p",href:"/docs/3.0/sql-manual/sql-statements/Cluster-Management-Statements/ALTER-SYSTEM-ADD-BACKEND"},"ADD BACKEND")," and ",(0,o.yg)("a",{parentName:"p",href:"/docs/3.0/sql-manual/sql-statements/Cluster-Management-Statements/ALTER-SYSTEM-DROP-BACKEND"},"REMOVE BACKEND"),".")),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Verify Backend Status:"),(0,o.yg)("p",{parentName:"li"},"Check the Backend log file (",(0,o.yg)("inlineCode",{parentName:"p"},"be.log"),") to ensure it has successfully started and joined the cluster."),(0,o.yg)("p",{parentName:"li"},"You can also use the following SQL command to check the Backend status:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-sql"},"SHOW BACKENDS;\n")),(0,o.yg)("p",{parentName:"li"},"This will display all Backends in the cluster and their current status."))),(0,o.yg)("h2",{id:"6-create-storage-vault"},"6. Create Storage Vault"),(0,o.yg)("p",null,"Storage Vault is an important component in the Doris decoupled storage and computing architecture. They represent a shared storage layer for storing data. You can create one or more Storage Vaults using HDFS or S3-compatible object storage. One Storage Vault can be set as the default Storage Vault, and system tables and tables without a specified Storage Vault will be stored in this default Storage Vault. The default Storage Vault cannot be deleted. Here are the methods to create a Storage Vault for your Doris cluster:"),(0,o.yg)("h3",{id:"61-create-hdfs-storage-vault"},"6.1 Create HDFS Storage Vault"),(0,o.yg)("p",null,"To create a Storage Vault using SQL, connect to your Doris cluster using a MySQL client."),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-sql"},'CREATE STORAGE VAULT IF NOT EXISTS hdfs_vault\n    PROPERTIES (\n    "type"="hdfs",\n    "fs.defaultFS"="hdfs://127.0.0.1:8020"\n    );\n')),(0,o.yg)("h3",{id:"62-create-s3-storage-vault"},"6.2 Create S3 Storage Vault"),(0,o.yg)("p",null,"To create a Storage Vault using S3-compatible object storage, follow these steps:"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Connect to your Doris cluster using a MySQL client.")),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Execute the following SQL command to create an S3 Storage Vault:"))),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-sql"},'CREATE STORAGE VAULT IF NOT EXISTS s3_vault\n    PROPERTIES (\n    "type"="S3",\n    "s3.endpoint"="s3.us-east-1.amazonaws.com",\n    "s3.access_key" = "ak",\n    "s3.secret_key" = "sk",\n    "s3.region" = "us-east-1",\n    "s3.root.path" = "ssb_sf1_p2_s3",\n    "s3.bucket" = "doris-build-1308700295",\n    "provider" = "S3"\n    );\n')),(0,o.yg)("p",null,"To create a Storage Vault on other object storage, please refer to ",(0,o.yg)("a",{parentName:"p",href:"/docs/3.0/sql-manual/sql-statements/Data-Definition-Statements/Create/CREATE-STORAGE-VAULT"},"Create Storage Vault"),"."),(0,o.yg)("h3",{id:"63-set-default-storage-vault"},"6.3 Set Default Storage Vault"),(0,o.yg)("p",null,"Use the following SQL statement to set a default Storage Vault."),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-sql"},"SET <storage_vault_name> AS DEFAULT STORAGE VAULT\n")),(0,o.yg)("h2",{id:"7-notes"},"7. Notes"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Only the Meta Service process for metadata operations should be configured as the ",(0,o.yg)("inlineCode",{parentName:"li"},"meta_service_endpoint")," target for FE and BE."),(0,o.yg)("li",{parentName:"ul"},"The data recycling function process should not be configured as the ",(0,o.yg)("inlineCode",{parentName:"li"},"meta_service_endpoint")," target.")))}u.isMDXComponent=!0}}]);