"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([[235081],{15680:(e,a,t)=>{t.d(a,{xA:()=>d,yg:()=>g});var n=t(296540);function l(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){l(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function o(e,a){if(null==e)return{};var t,n,l=function(e,a){if(null==e)return{};var t,n,l={},r=Object.keys(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||(l[t]=e[t]);return l}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(l[t]=e[t])}return l}var s=n.createContext({}),p=function(e){var a=n.useContext(s),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},d=function(e){var a=p(e.components);return n.createElement(s.Provider,{value:a},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},u=n.forwardRef((function(e,a){var t=e.components,l=e.mdxType,r=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),m=p(t),u=l,g=m["".concat(s,".").concat(u)]||m[u]||c[u]||r;return t?n.createElement(g,i(i({ref:a},d),{},{components:t})):n.createElement(g,i({ref:a},d))}));function g(e,a){var t=arguments,l=a&&a.mdxType;if("string"==typeof e||l){var r=t.length,i=new Array(r);i[0]=u;var o={};for(var s in a)hasOwnProperty.call(a,s)&&(o[s]=a[s]);o.originalType=e,o[m]="string"==typeof e?e:l,i[1]=o;for(var p=2;p<r;p++)i[p]=t[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}u.displayName="MDXCreateElement"},586837:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>s,contentTitle:()=>i,default:()=>c,frontMatter:()=>r,metadata:()=>o,toc:()=>p});var n=t(58168),l=(t(296540),t(15680));const r={title:"Batch Deletion",language:"en"},i=void 0,o={unversionedId:"data-operate/delete/batch-delete-manual",id:"data-operate/delete/batch-delete-manual",title:"Batch Deletion",description:"\x3c!--",source:"@site/docs/data-operate/delete/batch-delete-manual.md",sourceDirName:"data-operate/delete",slug:"/data-operate/delete/batch-delete-manual",permalink:"/docs/dev/data-operate/delete/batch-delete-manual",draft:!1,tags:[],version:"current",frontMatter:{title:"Batch Deletion",language:"en"},sidebar:"docs",previous:{title:"Deleting Data with DELETE Command",permalink:"/docs/dev/data-operate/delete/delete-manual"},next:{title:"Deleting Data with TRUNCATE Command",permalink:"/docs/dev/data-operate/delete/truncate-manual"}},s={},p=[{value:"Fundamental",id:"fundamental",level:2},{value:"Syntax Description",id:"syntax-description",level:2},{value:"Stream Load",id:"stream-load",level:3},{value:"Broker Load",id:"broker-load",level:3},{value:"Routine Load",id:"routine-load",level:3},{value:"Note",id:"note",level:2},{value:"Usage Examples",id:"usage-examples",level:2},{value:"Check if Batch Delete Support is Enabled",id:"check-if-batch-delete-support-is-enabled",level:3},{value:"Stream Load Usage Examples",id:"stream-load-usage-examples",level:3}],d={toc:p},m="wrapper";function c(e){let{components:a,...t}=e;return(0,l.yg)(m,(0,n.A)({},d,t,{components:a,mdxType:"MDXLayout"}),(0,l.yg)("p",null,"Why do we need to introduce import-based Batch Delete when we have the Delete operation?"),(0,l.yg)("ul",null,(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("strong",{parentName:"li"},"Limitations of Delete operation"))),(0,l.yg)("p",null,"When you delete by Delete statement, each execution of Delete generates an empty rowset to record the deletion conditions and a new version of the data. Each time you read, you have to filter the deletion conditions. If you delete too often or have too many deletion conditions, it will seriously affect the query performance."),(0,l.yg)("ul",null,(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("strong",{parentName:"li"},"Insert data interspersed with Delete data"))),(0,l.yg)("p",null,"For scenarios like importing data from a transactional database via CDC, Insert and Delete are usually interspersed in the data. In this case, the current Delete operation cannot be implemented."),(0,l.yg)("p",null,"When importing data, there are several ways to merge it:"),(0,l.yg)("ol",null,(0,l.yg)("li",{parentName:"ol"},(0,l.yg)("p",{parentName:"li"},"APPEND: Append all data to existing data.")),(0,l.yg)("li",{parentName:"ol"},(0,l.yg)("p",{parentName:"li"},"DELETE: Delete all rows that have the same value as the key column of the imported data (when a ",(0,l.yg)("inlineCode",{parentName:"p"},"sequence")," column exists in the table, it is necessary to satisfy the logic of having the same primary key as well as the size of the sequence column in order to delete it correctly, see Use Case 4 below for details).")),(0,l.yg)("li",{parentName:"ol"},(0,l.yg)("p",{parentName:"li"},"MERGE: APPEND or DELETE according to DELETE ON decision"))),(0,l.yg)("admonition",{title:"Warning",type:"caution"},(0,l.yg)("p",{parentName:"admonition"},"Batch Delete only works on Unique models.")),(0,l.yg)("h2",{id:"fundamental"},"Fundamental"),(0,l.yg)("p",null,"This is achieved by adding a hidden column ",(0,l.yg)("inlineCode",{parentName:"p"},"__DORIS_DELETE_SIGN__")," to the Unique table."),(0,l.yg)("p",null,"When FE parses the query, ",(0,l.yg)("inlineCode",{parentName:"p"},"__DORIS_DELETE_SIGN__")," is removed when it encounters * and so on, and ",(0,l.yg)("inlineCode",{parentName:"p"},"__DORIS_DELETE_SIGN__ !")," ",(0,l.yg)("inlineCode",{parentName:"p"},"= true"),", BE will add a column for judgement when reading, and determine whether to delete by the condition."),(0,l.yg)("ul",null,(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("p",{parentName:"li"},"Import"),(0,l.yg)("p",{parentName:"li"},"  On import, the value of the hidden column is set to the value of the ",(0,l.yg)("inlineCode",{parentName:"p"},"DELETE ON")," expression during the FE parsing stage.")),(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("p",{parentName:"li"},"Read"),(0,l.yg)("p",{parentName:"li"},"  The read adds ",(0,l.yg)("inlineCode",{parentName:"p"},"__DORIS_DELETE_SIGN__ !")," ",(0,l.yg)("inlineCode",{parentName:"p"},"= true")," condition, BE does not sense this process and executes normally.")),(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("p",{parentName:"li"},"Cumulative Compaction"),(0,l.yg)("p",{parentName:"li"},"  In Cumulative Compaction, hidden columns are treated as normal columns and the Compaction logic remains unchanged.")),(0,l.yg)("li",{parentName:"ul"},(0,l.yg)("p",{parentName:"li"},"Base Compaction"),(0,l.yg)("p",{parentName:"li"},"  When Base Compaction is performed, the rows marked for deletion are deleted to reduce the space occupied by the data."))),(0,l.yg)("h2",{id:"syntax-description"},"Syntax Description"),(0,l.yg)("p",null,"The syntax design of the import is mainly to add a column mapping that specifies the field of the delete marker column, and it is necessary to add a column to the imported data. The syntax of various import methods is as follows:"),(0,l.yg)("h3",{id:"stream-load"},"Stream Load"),(0,l.yg)("p",null,"The writing method of ",(0,l.yg)("inlineCode",{parentName:"p"},"Stream Load")," adds a field to set the delete label column in the columns field in the header. Example: ",(0,l.yg)("inlineCode",{parentName:"p"},'-H "columns: k1, k2, label_c3" -H "merge_type: [MERGE|APPEND|DELETE]" -H "delete: label_c3=1"')),(0,l.yg)("h3",{id:"broker-load"},"Broker Load"),(0,l.yg)("p",null,"The writing method of ",(0,l.yg)("inlineCode",{parentName:"p"},"Broker Load")," sets the field of the delete marker column at ",(0,l.yg)("inlineCode",{parentName:"p"},"PROPERTIES"),". The syntax is as follows:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-sql"},'LOAD LABEL db1.label1\n(\n    [MERGE|APPEND|DELETE] DATA INFILE("hdfs://abc.com:8888/user/palo/test/ml/file1")\n    INTO TABLE tbl1\n    COLUMNS TERMINATED BY ","\n    (tmp_c1,tmp_c2, label_c3)\n    SET\n    (\n        id=tmp_c2,\n        name=tmp_c1,\n    )\n    [DELETE ON label_c3=true]\n)\nWITH BROKER \'broker\'\n(\n    "username"="user",\n    "password"="pass"\n)\nPROPERTIES\n(\n    "timeout" = "3600"\n);\n')),(0,l.yg)("h3",{id:"routine-load"},"Routine Load"),(0,l.yg)("p",null,"The writing method of ",(0,l.yg)("inlineCode",{parentName:"p"},"Routine Load")," adds a mapping to the ",(0,l.yg)("inlineCode",{parentName:"p"},"columns")," field. The mapping method is the same as above. The syntax is as follows:"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-sql"},'CREATE ROUTINE LOAD example_db.test1 ON example_tbl \n [WITH MERGE|APPEND|DELETE]\n COLUMNS(k1, k2, k3, v1, v2, label),\n WHERE k1  100 and k2 like "%doris%"\n [DELETE ON label=true]\n PROPERTIES\n (\n     "desired_concurrent_number"="3",\n     "max_batch_interval" = "20",\n     "max_batch_rows" = "300000",\n     "max_batch_size" = "209715200",\n     "strict_mode" = "false"\n )\n FROM KAFKA\n (\n     "kafka_broker_list" = "broker1:9092,broker2:9092,broker3:9092",\n     "kafka_topic" = "my_topic",\n     "kafka_partitions" = "0,1,2,3",\n     "kafka_offsets" = "101,0,0,200"\n );\n')),(0,l.yg)("h2",{id:"note"},"Note"),(0,l.yg)("ol",null,(0,l.yg)("li",{parentName:"ol"},(0,l.yg)("p",{parentName:"li"},"Since import operations other than stream load may be executed out of order inside doris, if it is not stream load when importing using the ",(0,l.yg)("inlineCode",{parentName:"p"},"MERGE")," method, it needs to be used with load sequence. For the specific syntax, please refer to the ",(0,l.yg)("inlineCode",{parentName:"p"},"sequence")," column related documents")),(0,l.yg)("li",{parentName:"ol"},(0,l.yg)("p",{parentName:"li"},(0,l.yg)("inlineCode",{parentName:"p"},"DELETE ON")," condition can only be used with MERGE."))),(0,l.yg)("admonition",{title:"Tip",type:"tip"},(0,l.yg)("p",{parentName:"admonition"},"if session variable ",(0,l.yg)("inlineCode",{parentName:"p"},"SET show_hidden_columns = true")," was executed before running import task to show whether table support batch delete feature, then execute ",(0,l.yg)("inlineCode",{parentName:"p"},"select count(*) from xxx")," statement in the same session after finishing ",(0,l.yg)("inlineCode",{parentName:"p"},"DELETE/MERGE")," import task, it will result in a unexpected result that the statement result set will include the deleted results. To avoid this problem, you should execute ",(0,l.yg)("inlineCode",{parentName:"p"},"SET show_hidden_columns = false")," before selecting statement or open a new session to run the select statement.")),(0,l.yg)("h2",{id:"usage-examples"},"Usage Examples"),(0,l.yg)("h3",{id:"check-if-batch-delete-support-is-enabled"},"Check if Batch Delete Support is Enabled"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-sql"},'mysql> CREATE TABLE IF NOT EXISTS table1 (\n    ->     siteid INT,\n    ->     citycode INT,\n    ->     username VARCHAR(64),\n    ->     pv BIGINT\n    -> ) UNIQUE KEY (siteid, citycode, username)\n    -> DISTRIBUTED BY HASH(siteid) BUCKETS 10\n    -> PROPERTIES (\n    ->     "replication_num" = "3"\n    -> );\nQuery OK, 0 rows affected (0.34 sec)\n\nmysql> SET show_hidden_columns=true;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> DESC table1;\n+-----------------------+-------------+------+-------+---------+-------+\n| Field                 | Type        | Null | Key   | Default | Extra |\n+-----------------------+-------------+------+-------+---------+-------+\n| siteid                | int         | Yes  | true  | NULL    |       |\n| citycode              | int         | Yes  | true  | NULL    |       |\n| username              | varchar(64) | Yes  | true  | NULL    |       |\n| pv                    | bigint      | Yes  | false | NULL    | NONE  |\n| __DORIS_DELETE_SIGN__ | tinyint     | No   | false | 0       | NONE  |\n| __DORIS_VERSION_COL__ | bigint      | No   | false | 0       | NONE  |\n+-----------------------+-------------+------+-------+---------+-------+\n6 rows in set (0.01 sec)\n')),(0,l.yg)("h3",{id:"stream-load-usage-examples"},"Stream Load Usage Examples"),(0,l.yg)("ol",null,(0,l.yg)("li",{parentName:"ol"},(0,l.yg)("p",{parentName:"li"},"Import data normally:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-shell"},'curl --location-trusted -u root: -H "column_separator:," -H "columns: siteid, citycode, username, pv" -H "merge_type: APPEND" -T ~/table1_data http://127.0.0.1:8030/api/test/table1/_stream_load\n')),(0,l.yg)("p",{parentName:"li"},"The APPEND condition can be omitted, which has the same effect as the following statement:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-shell"},'curl --location-trusted -u root: -H "column_separator:," -H "columns: siteid, citycode, username, pv" -T ~/table1_data http://127.0.0.1:8030/api/test/table1/_stream_load\n'))),(0,l.yg)("li",{parentName:"ol"},(0,l.yg)("p",{parentName:"li"},"Delete all data with the same key as the imported data"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-Shell"},'curl --location-trusted -u root: -H "column_separator:," -H "columns: siteid, citycode, username, pv" -H "merge_type: DELETE" -T ~/table1_data http://127.0.0.1:8030/api/test/table1/_stream_load\n')),(0,l.yg)("p",{parentName:"li"},"Before load:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-sql"},"+--------+----------+----------+------+\n| siteid | citycode | username | pv   |\n+--------+----------+----------+------+\n|      3 |        2 | tom      |    2 |\n|      4 |        3 | bush     |    3 |\n|      5 |        3 | helen    |    3 |\n+--------+----------+----------+------+\n")),(0,l.yg)("p",{parentName:"li"},"Load data:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-Plain"},"3,2,tom,0\n")),(0,l.yg)("p",{parentName:"li"},"After load:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-sql"},"+--------+----------+----------+------+\n| siteid | citycode | username | pv   |\n+--------+----------+----------+------+\n|      4 |        3 | bush     |    3 |\n|      5 |        3 | helen    |    3 |\n+--------+----------+----------+------+\n"))),(0,l.yg)("li",{parentName:"ol"},(0,l.yg)("p",{parentName:"li"},"Import the same row as the key column of the row with ",(0,l.yg)("inlineCode",{parentName:"p"},"site_id=1")),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-shell"},'curl --location-trusted -u root: -H "column_separator:," -H "columns: siteid, citycode, username, pv" -H "merge_type: MERGE" -H "delete: siteid=1" -T ~/ table1_data http://127.0.0.1:8030/api/test/table1/_stream_load\n')),(0,l.yg)("p",{parentName:"li"},"Before load:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-sql"},"+--------+----------+----------+------+\n| siteid | citycode | username | pv   |\n+--------+----------+----------+------+\n|      4 |        3 | bush     |    3 |\n|      5 |        3 | helen    |    3 |\n|      1 |        1 | jim      |    2 |\n+--------+----------+----------+------+\n")),(0,l.yg)("p",{parentName:"li"},"Load data:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-Plain"},"2,1,grace,2\n3,2,tom,2\n1,1,jim,2\n")),(0,l.yg)("p",{parentName:"li"},"After load:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-sql"},"+--------+----------+----------+------+\n| siteid | citycode | username | pv   |\n+--------+----------+----------+------+\n|      4 |        3 | bush     |    3 |\n|      2 |        1 | grace    |    2 |\n|      3 |        2 | tom      |    2 |\n|      5 |        3 | helen    |    3 |\n+--------+----------+----------+------+\n"))),(0,l.yg)("li",{parentName:"ol"},(0,l.yg)("p",{parentName:"li"},"When the table has the sequence column, delete all data with the same key as the imported data"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-shell"},'curl --location-trusted -u root: -H "column_separator:," -H "columns: name, gender, age" -H "function_column.sequence_col: age" -H "merge_type: DELETE"  -T ~/table1_data http://127.0.0.1:8030/api/test/table1/_stream_load\n')),(0,l.yg)("p",{parentName:"li"},"When the unique table has the sequence column, sequence column is used as the basis for the replacement order of the REPLACE aggregate function under the same key column, and the larger value can replace the smaller value. If you want delete some data, the imported data must have the same key and the sequence column must be larger or equal than before."),(0,l.yg)("p",{parentName:"li"},"For example, one table like this:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-sql"},"mysql> SET show_hidden_columns=true;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> DESC table1;\n+------------------------+--------------+------+-------+---------+---------+\n| Field                  | Type         | Null | Key   | Default | Extra   |\n+------------------------+--------------+------+-------+---------+---------+\n| name                   | VARCHAR(100) | No   | true  | NULL    |         |\n| gender                 | VARCHAR(10)  | Yes  | false | NULL    | REPLACE |\n| age                    | INT          | Yes  | false | NULL    | REPLACE |\n| __DORIS_DELETE_SIGN__  | TINYINT      | No   | false | 0       | REPLACE |\n| __DORIS_SEQUENCE_COL__ | INT          | Yes  | false | NULL    | REPLACE |\n+------------------------+--------------+------+-------+---------+---------+\n4 rows in set (0.00 sec)\n")),(0,l.yg)("p",{parentName:"li"},"Before load:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-sql"},"+-------+--------+------+\n| name  | gender | age  |\n+-------+--------+------+\n| li    | male   |   10 |\n| wang  | male   |   14 |\n| zhang | male   |   12 |\n+-------+--------+------+\n")),(0,l.yg)("p",{parentName:"li"},"If you load data like this:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-Plain"},"li,male,10\n")),(0,l.yg)("p",{parentName:"li"},"After load:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-sql"},"+-------+--------+------+\n| name  | gender | age  |\n+-------+--------+------+\n| wang  | male   |   14 |\n| zhang | male   |   12 |\n+-------+--------+------+\n")),(0,l.yg)("p",{parentName:"li"},"You will find that the data is deleted."),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-Plain"},"li,male,10\n")),(0,l.yg)("p",{parentName:"li"},"But if you load data like this:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-Plain"},"li,male,9\n")),(0,l.yg)("p",{parentName:"li"},"After load:"),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-sql"},"+-------+--------+------+\n| name  | gender | age  |\n+-------+--------+------+\n| li    | male   |   10 |\n| wang  | male   |   14 |\n| zhang | male   |   12 |\n+-------+--------+------+\n")),(0,l.yg)("p",{parentName:"li"},"You will find that the data is not deleted."),(0,l.yg)("pre",{parentName:"li"},(0,l.yg)("code",{parentName:"pre",className:"language-Plain"},"li,male,10\n")),(0,l.yg)("p",{parentName:"li"},"This is because in the underlying dependencies, it will first judge the case of the same key, display the row data with a large value in the sequence column, and then check whether the ",(0,l.yg)("inlineCode",{parentName:"p"},"__DORIS_DELETE_SIGN__")," value of the row is 1. If it is 1, it will not be displayed. If it is 0, it will still be read out."))),(0,l.yg)("admonition",{title:"Tip",type:"tip"},(0,l.yg)("p",{parentName:"admonition"},"When data is written and deleted at the same time in the imported data (e.g., in the Flink CDC scenario), using the sequence column can effectively ensure consistency when the data arrives out of order, avoiding the deletion operation of an old version that arrives later, and accidentally deleting the new version of the data that arrives first.")))}c.isMDXComponent=!0}}]);